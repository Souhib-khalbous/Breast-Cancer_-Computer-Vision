{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class ConvNext(nn.Module):\n",
    "\tdef __init__(self, num_classes=4):\n",
    "\t\tsuper(ConvNext, self).__init__()\n",
    "\t\t\n",
    "\t\tself.convnext = models.convnext_small(pretrained=True)\n",
    "\t\tself.convnext2 = models.convnext_small(pretrained=True)\n",
    "\t\tself.convnext3 = models.convnext_small(pretrained=True)\n",
    "\t\tself.convnext4 = models.convnext_small(pretrained=True)\n",
    "\n",
    "\t\t# Replace the classifiers with identities to extract features\n",
    "\t\tself.convnext.classifier[2] = nn.Identity()\n",
    "\t\tself.convnext2.classifier[2] = nn.Identity()\n",
    "\t\tself.convnext3.classifier[2] = nn.Identity()\n",
    "\t\tself.convnext4.classifier[2] = nn.Identity()\n",
    "\t\t\n",
    "\t\tself.fc = nn.Sequential(\n",
    "\t\t\tnn.Linear(3072  , 512),\n",
    "\t\t\tnn.Dropout(0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, image,image2):\n",
    "\t\tB, C, H, W = image.size()\n",
    "\t\t\n",
    "\t\tif H % 2 != 0 or W % 2 != 0:\n",
    "\t\t\traise ValueError(\"Image height and width must be divisible by 2.\")\n",
    "\t\t\n",
    "\t\ttop_left = image[:, :, :H//2, :W//2]\n",
    "\t\ttop_right = image[:, :, :H//2, W//2:]\n",
    "\t\tbottom_left = image[:, :, H//2:, :W//2]\n",
    "\t\tbottom_right = image[:, :, H//2:, W//2:]\n",
    "\t\t\n",
    "\t\tfeatures1 = self.convnext(top_left)\n",
    "\t\tfeatures2 = self.convnext2(top_right)\n",
    "\t\tfeatures3 = self.convnext3(bottom_left)\n",
    "\t\tfeatures4 = self.convnext4(bottom_right)\n",
    "\t\t\n",
    "\t\tcombined_features = torch.cat((features1, features2, features3, features4), dim=1)\n",
    "\t\t\n",
    "\t\toutput = self.fc(combined_features.view(combined_features.size(0), -1))\n",
    "\t\t\n",
    "\t\treturn output\n",
    "\n",
    "\n",
    "\n",
    "class SWIN(nn.Module):\n",
    "\tdef __init__(self, num_classes=4):\n",
    "\t\tsuper(SWIN, self).__init__()\n",
    "\t\t\n",
    "\t\tself.swin = models.swin_b(pretrained=True)\n",
    "\t\tself.swin2 = models.swin_b(pretrained=True)\n",
    "\t\tself.swin3 = models.swin_b(pretrained=True)\n",
    "\t\tself.swin4 = models.swin_b(pretrained=True)\n",
    "\n",
    "\t\t# Replace the classifiers with identities to extract features\n",
    "\t\tself.swin.head = nn.Identity()\n",
    "\t\tself.swin2.head = nn.Identity()\n",
    "\t\tself.swin3.head = nn.Identity()\n",
    "\t\tself.swin4.head = nn.Identity()\n",
    "\t\t\n",
    "\t\tself.fc = nn.Sequential(\n",
    "\t\t\tnn.Linear(4096  , 512),\n",
    "\t\t\tnn.Dropout(0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, image,image2):\n",
    "\t\tB, C, H, W = image.size()\n",
    "\t\t\n",
    "\t\tif H % 2 != 0 or W % 2 != 0:\n",
    "\t\t\traise ValueError(\"Image height and width must be divisible by 2.\")\n",
    "\t\t\n",
    "\t\ttop_left = image[:, :, :H//2, :W//2]\n",
    "\t\ttop_right = image[:, :, :H//2, W//2:]\n",
    "\t\tbottom_left = image[:, :, H//2:, :W//2]\n",
    "\t\tbottom_right = image[:, :, H//2:, W//2:]\n",
    "\t\t\n",
    "\t\tfeatures1 = self.swin(top_left)\n",
    "\t\tfeatures2 = self.swin2(top_right)\n",
    "\t\tfeatures3 = self.swin3(bottom_left)\n",
    "\t\tfeatures4 = self.swin4(bottom_right)\n",
    "\t\t\n",
    "\t\tcombined_features = torch.cat((features1, features2, features3, features4), dim=1)\n",
    "\t\t\n",
    "\t\toutput = self.fc(combined_features.view(combined_features.size(0), -1))\n",
    "\t\t\n",
    "\t\treturn output\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CombinedModel(nn.Module):\n",
    "\tdef __init__(self, num_classes=4):\n",
    "\t\tsuper(CombinedModel, self).__init__()\n",
    "\t\t\n",
    "\t\tself.convNext = ConvNext()\n",
    "\t\tself.swin = SWIN()\n",
    "\t\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\t\t\n",
    "\t\tself.convNext.load_state_dict(torch.load('./Saved/4x-ConvNext-E10-448.pt', map_location=device))\n",
    "\t\tself.swin.load_state_dict(torch.load('./Saved/4x-SWIN-E16-448.pt', map_location=device))\n",
    "\t\t\n",
    "\t\t# Replace the classifiers with identities to extract features\n",
    "\t\tself.convNext.fc = nn.Identity()\n",
    "\t\tself.swin.fc = nn.Identity()\n",
    "\n",
    "\n",
    "\t\tself.fc = nn.Sequential(\n",
    "            nn.Linear(7168, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "\tdef forward(self, image1):\n",
    "\t\tfeatures1 = self.convNext(image1, '')\n",
    "\t\tfeatures3 = self.swin(image1, '')\n",
    "\t\tcombined_features = torch.cat((features1,features3), dim=1)\t\t\n",
    "\t\t\n",
    "\t\toutput = self.fc(combined_features)\n",
    "\t\t\n",
    "\t\treturn output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Resize((448, 448)),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "\tdef __init__(self, image_dir, transform=None):\n",
    "\t\tself.image_dir = image_dir\n",
    "\t\tself.transform = transform\n",
    "\t\tself.image_labels = []\n",
    "\t\tfor folder in os.listdir(image_dir):\n",
    "\t\t\tif '1' in folder:\n",
    "\t\t\t\tlabel = 0\n",
    "\t\t\telif '2' in folder:\n",
    "\t\t\t\tlabel = 1\n",
    "\t\t\telif '4' in folder:\n",
    "\t\t\t\tlabel = 2\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabel = 3\n",
    "\n",
    "\t\t\tfor sub_folder in tqdm(os.listdir(os.path.join(image_dir, folder))):\n",
    "\t\t\t\tfiles = os.listdir(os.path.join(image_dir, folder, sub_folder))\n",
    "\t\t\t\tif len(files) == 2:\n",
    "\t\t\t\t\tif 'CC' in files[0]:\n",
    "\t\t\t\t\t\tfile1 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\t\t\t\t\t\tfile2 = os.path.join(image_dir, folder, sub_folder, files[1])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfile1 = os.path.join(image_dir, folder, sub_folder, files[1])\n",
    "\t\t\t\t\t\tfile2 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfile1 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\t\t\t\t\tfile2 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\n",
    "\t\t\t\timage1PIL = cv.imread(file1)\n",
    "\t\t\t\timage2PIL = cv.imread(file2)\n",
    "\t\t\t\t\n",
    "\t\t\t\tcombined_image = cv.hconcat([image1PIL, image2PIL])\n",
    "\t\t\t\tlabel = int(label)  \n",
    "\t\t\t\tcombined_image = Image.fromarray(combined_image)\n",
    "\t\t\t\tif self.transform:\n",
    "\t\t\t\t\timage1 = self.transform(combined_image)\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.image_labels.append((image1, image1, label))\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.image_labels)\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage1, image2, label = self.image_labels[idx]\n",
    "\t\t\n",
    "\t\t\n",
    "\t\treturn image1, label\n",
    "\n",
    "trainPath = \"./Data-448/\"\n",
    "valPath = \"./Data-448-Val/\"\n",
    "\n",
    "print(\"Creating Custom Data\")\n",
    "train_dataset = CustomImageDataset(image_dir=trainPath, transform=transform)\n",
    "val_dataset = CustomImageDataset(image_dir=valPath, transform=transform)\n",
    "\n",
    "\n",
    "def get_batches(dataset, batch_size, shuffle=True):\n",
    "\tindices = np.arange(len(dataset))\n",
    "\tif shuffle:\n",
    "\t\tnp.random.shuffle(indices)\n",
    "\tfor start_idx in range(0, len(dataset), batch_size):\n",
    "\t\tbatch_indices = indices[start_idx:start_idx + batch_size]\n",
    "\t\tbatch = [dataset[idx] for idx in batch_indices]\n",
    "\t\timage1s, labels = zip(*batch)\n",
    "\t\timage1s = torch.stack(image1s)\n",
    "\t\tlabels = torch.tensor(labels)\n",
    "\t\tyield image1s, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model):\n",
    "    for param in model.convNext.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.swin.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_layers(model):\n",
    "    for param in model.convNext.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.swin.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_train = [label for _, label in train_dataset]\n",
    "device = torch.device(3)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "model = CombinedModel(num_classes=4)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=3e-4, momentum=0.9)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "\n",
    "\t\t\n",
    "def train_model(model, train_dataset, val_dataset, criterion, optimizer, num_epochs=10, batch_size=16):\n",
    "\t\n",
    "\tmodel.to(device)\n",
    "\tfreeze_layers(model)\n",
    "\t\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\t\t\n",
    "\t\tfor i, (image1s, labels) in enumerate(get_batches(train_dataset, batch_size, shuffle=True)):\n",
    "\t\t\timage1s, labels = image1s.to(device), labels.to(device)\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(image1s)\n",
    "\t\t\tlabels = labels.long()  # Ensure labels are LongTensor\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\t\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\t# Print loss for this batch\n",
    "\t\t\tprint(f'Epoch {epoch+1}/{num_epochs}, Step {i+1}, Loss: {loss.item():.6f}')\n",
    "\t\t\t\n",
    "\t\t\trunning_loss += loss.item() * image1s.size(0) \n",
    "\n",
    "\t\t# Calculate and print average loss for this epoch\n",
    "\t\tepoch_loss = running_loss / len(train_dataset)\n",
    "\t\tprint(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {epoch_loss:.4f}')\n",
    "\t\t\n",
    "\t\t# Validation (optional, to track performance on validation data)\n",
    "\t\tmodel.eval()\n",
    "\t\tval_loss = 0.0\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor image1s, labels in get_batches(val_dataset, batch_size, shuffle=False):\n",
    "\t\t\t\timage1s, labels = image1s.to(device), labels.to(device)\n",
    "\t\t\t\toutputs = model(image1s)\n",
    "\t\t\t\tlabels = labels.long()  # Ensure labels are LongTensor\n",
    "\t\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\t\t\n",
    "\t\t\t\tval_loss += loss.item() * image1s.size(0)\n",
    "\t\t\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\t\t\ttotal += labels.size(0)\n",
    "\t\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\t\t\n",
    "\t\tval_loss /= len(val_dataset)\n",
    "\t\tval_accuracy = correct / total * 100\n",
    "\t\tprint(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "\t\ttorch.save(model.state_dict(), './Models/model' + str(epoch + 3) + '.pt')\n",
    "\n",
    "train_model(model, train_dataset, val_dataset, criterion, optimizer, num_epochs=1, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "model = CombinedModel(num_classes=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('.\\Models\\model3.pt', map_location=device))\n",
    "def evaluate_model(model, testData, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image1s, labels in get_batches(testData, 8, shuffle=False):\n",
    "            image1s, labels = image1s.to(device), labels.to(device)\n",
    "            outputs = model(image1s)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    return cm, f1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "evaluate_model(model, val_dataset, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
