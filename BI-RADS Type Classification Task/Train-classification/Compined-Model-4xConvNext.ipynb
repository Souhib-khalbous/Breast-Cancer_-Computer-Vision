{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "\tdef __init__(self, num_classes=4):\n",
    "\t\tsuper(CombinedModel, self).__init__()\n",
    "\t\t\n",
    "\t\tself.convnext = models.convnext_small(pretrained=True)\n",
    "\t\tself.convnext2 = models.convnext_small(pretrained=True)\n",
    "\t\tself.convnext3 = models.convnext_small(pretrained=True)\n",
    "\t\tself.convnext4 = models.convnext_small(pretrained=True)\n",
    "\n",
    "\t\t# Replace the classifiers with identities to extract features\n",
    "\t\tself.convnext.classifier[2] = nn.Identity()\n",
    "\t\tself.convnext2.classifier[2] = nn.Identity()\n",
    "\t\tself.convnext3.classifier[2] = nn.Identity()\n",
    "\t\tself.convnext4.classifier[2] = nn.Identity()\n",
    "\t\t\n",
    "\t\tself.fc = nn.Sequential(\n",
    "\t\t\tnn.Linear(7168  , 512),\n",
    "\t\t\tnn.Dropout(0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(512, num_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, image,image2):\n",
    "\t\tB, C, H, W = image.size()\n",
    "\t\t\n",
    "\t\tif H % 2 != 0 or W % 2 != 0:\n",
    "\t\t\traise ValueError(\"Image height and width must be divisible by 2.\")\n",
    "\t\t\n",
    "\t\ttop_left = image[:, :, :H//2, :W//2]\n",
    "\t\ttop_right = image[:, :, :H//2, W//2:]\n",
    "\t\tbottom_left = image[:, :, H//2:, :W//2]\n",
    "\t\tbottom_right = image[:, :, H//2:, W//2:]\n",
    "\t\t\n",
    "\t\tfeatures1 = self.convnext(top_left)\n",
    "\t\tfeatures2 = self.convnext2(top_right)\n",
    "\t\tfeatures3 = self.convnext3(bottom_left)\n",
    "\t\tfeatures4 = self.convnext4(bottom_right)\n",
    "\t\t\n",
    "\t\tcombined_features = torch.cat((features1, features2, features3, features4), dim=1)\n",
    "\t\t\n",
    "\t\toutput = self.fc(combined_features.view(combined_features.size(0), -1))\n",
    "\t\t\n",
    "\t\treturn output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Custom Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2202/2202 [00:14<00:00, 150.29it/s]\n",
      "100%|██████████| 800/800 [00:05<00:00, 145.78it/s]\n",
      "100%|██████████| 800/800 [00:05<00:00, 143.21it/s]\n",
      "100%|██████████| 800/800 [00:05<00:00, 149.89it/s]\n",
      "100%|██████████| 800/800 [00:05<00:00, 148.19it/s]\n",
      "100%|██████████| 800/800 [00:05<00:00, 148.17it/s]\n",
      "100%|██████████| 800/800 [00:05<00:00, 149.18it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 156.25it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 154.99it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 157.23it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 157.23it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 157.23it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 157.23it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 157.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Resize((448, 448)),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "\tdef __init__(self, image_dir, transform=None):\n",
    "\t\tself.image_dir = image_dir\n",
    "\t\tself.transform = transform\n",
    "\t\tself.image_labels = []\n",
    "\t\tfor folder in os.listdir(image_dir):\n",
    "\t\t\tif '1' in folder:\n",
    "\t\t\t\tlabel = 0\n",
    "\t\t\telif '2' in folder:\n",
    "\t\t\t\tlabel = 1\n",
    "\t\t\telif '4' in folder:\n",
    "\t\t\t\tlabel = 2\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabel = 3\n",
    "\n",
    "\t\t\tfor sub_folder in tqdm(os.listdir(os.path.join(image_dir, folder))):\n",
    "\t\t\t\tfiles = os.listdir(os.path.join(image_dir, folder, sub_folder))\n",
    "\t\t\t\tif len(files) == 2:\n",
    "\t\t\t\t\tif 'CC' in files[0]:\n",
    "\t\t\t\t\t\tfile1 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\t\t\t\t\t\tfile2 = os.path.join(image_dir, folder, sub_folder, files[1])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfile1 = os.path.join(image_dir, folder, sub_folder, files[1])\n",
    "\t\t\t\t\t\tfile2 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfile1 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\t\t\t\t\tfile2 = os.path.join(image_dir, folder, sub_folder, files[0])\n",
    "\n",
    "\t\t\t\timage1PIL = cv.imread(file1)\n",
    "\t\t\t\timage2PIL = cv.imread(file2)\n",
    "\t\t\t\t\n",
    "\t\t\t\tcombined_image = cv.hconcat([image1PIL, image2PIL])\n",
    "\t\t\t\tlabel = int(label)  \n",
    "\t\t\t\tcombined_image = Image.fromarray(combined_image)\n",
    "\t\t\t\tif self.transform:\n",
    "\t\t\t\t\timage1 = self.transform(combined_image)\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.image_labels.append((image1, image1, label))\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.image_labels)\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage1, image2, label = self.image_labels[idx]\n",
    "\t\t\n",
    "\t\t\n",
    "\t\treturn image1, image2, label\n",
    "\n",
    "\n",
    "trainPath = \"./Data-448/\"\n",
    "valPath = \"./Data-448-Val/\"\n",
    "\n",
    "print(\"Creating Custom Data\")\n",
    "train_dataset = CustomImageDataset(image_dir=trainPath, transform=transform)\n",
    "val_dataset = CustomImageDataset(image_dir=valPath, transform=transform)\n",
    "# test_dataset = CustomImageDataset(image_dir=testPath, transform=transform)\n",
    "\n",
    "def get_batches(dataset, batch_size, shuffle=True):\n",
    "\tindices = np.arange(len(dataset))\n",
    "\tif shuffle:\n",
    "\t\tnp.random.shuffle(indices)\n",
    "\tfor start_idx in range(0, len(dataset), batch_size):\n",
    "\t\tbatch_indices = indices[start_idx:start_idx + batch_size]\n",
    "\t\tbatch = [dataset[idx] for idx in batch_indices]\n",
    "\t\timage1s,image2s, labels = zip(*batch)\n",
    "\t\timage1s = torch.stack(image1s)\n",
    "\t\timage2s = torch.stack(image2s)\n",
    "\t\tlabels = torch.tensor(labels)\n",
    "\t\tyield image1s,image2s, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_train = [label for _, _, label in train_dataset]\n",
    "device = torch.device(3)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "print(class_weights)\n",
    "model = CombinedModel(num_classes=4)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3e-4, momentum=0.9)\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "   \n",
    "def train_model(model, train_dataset, val_dataset, criterion, optimizer, num_epochs=10, batch_size=16):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        \n",
    "        for i, (image1s,image2s, labels) in enumerate(get_batches(train_dataset, batch_size, shuffle=True)):\n",
    "            image1s,image2s, labels = image1s.to(device),image2s.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(image1s,image2s)\n",
    "            labels = labels.long()  # Ensure labels are LongTensor\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print loss for this batch\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Step {i+1}, Loss: {loss.item():.6f}')\n",
    "            \n",
    "            running_loss += loss.item() * image1s.size(0) \n",
    "\n",
    "        # Calculate and print average loss for this epoch\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Validation (optional, to track performance on validation data)\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for image1s,image2s, labels in get_batches(val_dataset, batch_size, shuffle=False):\n",
    "                image1s,image2s, labels = image1s.to(device),image2s.to(device), labels.to(device)\n",
    "                outputs = model(image1s,image2s)\n",
    "                labels = labels.long()  # Ensure labels are LongTensor\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * image1s.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_dataset)\n",
    "        val_accuracy = correct / total * 100\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "        torch.save(model.state_dict(), './Models/model' + str(epoch) + '.pt')\n",
    "\n",
    "train_model(model, train_dataset, val_dataset, criterion, optimizer, num_epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\medicai\\AppData\\Local\\Temp\\ipykernel_21948\\2840706684.py:11: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  model.load_state_dict(torch.load('.\\Models\\model9.pt', map_location=device))\n",
      "c:\\Users\\medicai\\anaconda3\\envs\\nlp_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\medicai\\anaconda3\\envs\\nlp_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Small_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\medicai\\AppData\\Local\\Temp\\ipykernel_21948\\2840706684.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('.\\Models\\model9.pt', map_location=device))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[46,  3,  1,  0],\n",
       "        [11, 28, 10,  1],\n",
       "        [ 8,  5, 22, 15],\n",
       "        [ 0,  3,  9, 38]], dtype=int64),\n",
       " 0.6595608958701288)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "model = CombinedModel(num_classes=4)\n",
    "device = torch.device(3)\n",
    "model.to(device)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('.\\Models\\model9.pt', map_location=device))\n",
    "def evaluate_model(model, testData, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image1s,image2s, labels in get_batches(testData, 8, shuffle=False):\n",
    "            image1s, labels = image1s.to(device), labels.to(device)\n",
    "            outputs = model(image1s,image2s)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    return cm, f1\n",
    "\n",
    "evaluate_model(model, val_dataset, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.6596 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
